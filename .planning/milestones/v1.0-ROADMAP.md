# Milestone v1.0: Anthropic Support

**Status:** ✅ SHIPPED 2026-01-10
**Phases:** 1-9 + 9.1
**Total Plans:** 26

## Overview

Add native Anthropic Claude support as a first-class LLM provider in Sure. Users will be able to select between OpenAI and Anthropic through a settings UI dropdown, configure their API keys, and use all AI features (chat, auto-categorization, merchant detection) with their chosen provider. The implementation follows existing Sure patterns: Provider abstraction, registry pattern, and settings model with ENV fallbacks.

## Phases

### Phase 1: Foundation

**Goal**: Add Anthropic gem and create Provider::Anthropic class skeleton
**Depends on**: Nothing (first phase)
**Plans**: 3 plans

Plans:
- [x] 1-01: Add anthropic gem to Gemfile and bundle
- [x] 1-02: Create Provider::Anthropic class skeleton inheriting from Provider
- [x] 1-03: Implement client initialization and error handling

**Details:**
Added anthropic gem (~> 1.16.0) to Gemfile in AI section. Created Provider::Anthropic class inheriting from Provider with LlmConcept. Implemented Anthropic::Client initialization with api_key. Added Error subclass for provider-specific error handling. Added model query methods (supports_model?, provider_name). Implemented effective_model class method with ANTHROPIC_MODEL ENV fallback. DEFAULT_MODEL = "claude-sonnet-4-5-20250929" (balanced model for categorization/merchant detection).

---

### Phase 2: Core Operations

**Goal**: Implement auto_categorize and auto_detect_merchants with Anthropic
**Depends on**: Phase 1
**Plans**: 3 plans

Plans:
- [x] 2-01: Foundation - Add Anthropic gem and create Provider::Anthropic class skeleton
- [x] 2-02: Implement AutoCategorizer using Anthropic Messages API with structured outputs
- [x] 2-03: Implement auto_detect_merchants method using Anthropic Messages API

**Status**: Complete (2026-01-10)

**Details:**
Implemented Provider::Anthropic::AutoCategorizer and AutoMerchantDetector classes using Anthropic Messages API with structured outputs. Added error handling with Anthropic-specific error types. Implemented prompt and schema for merchant detection.

---

### Phase 3: Chat Support

**Goal**: Implement chat_response with Anthropic including function/tool calling
**Depends on**: Phase 2
**Plans**: 4 plans

Plans:
- [x] 3-01: Implement basic chat_response without tools
- [x] 3-02: Add tool/function calling support for chat
- [x] 3-03: Handle function results and multi-turn conversations
- [x] 3-04: Add streaming support (deferred for future work)

**Status**: Complete (2026-01-09)

**Details:**
Created Provider::Anthropic::ChatConfig for Anthropic Messages API message format. Created Provider::Anthropic::ChatParser for parsing Anthropic responses to LlmConcept::ChatResponse. Implemented chat_response method with system instructions support (via separate system parameter). Mapped Anthropic token fields (input/output_tokens -> prompt/completion_tokens) for LlmUsage. Added Langfuse tracing for Anthropic chat requests.

---

### Phase 4: Registry Integration

**Goal**: Register Anthropic in provider registry and add cost tracking
**Depends on**: Phase 3
**Plans**: 3 plans

Plans:
- [x] 4-01: Add anthropic method to Provider::Registry
- [x] 4-02: Add anthropic to LLM concept available providers
- [x] 4-03: Add Anthropic model pricing to LlmUsage.calculate_cost

**Status**: Complete (2026-01-09)

**Details:**
Added anthropic method to Provider::Registry following OpenAI pattern. Made Anthropic discoverable for LLM concept. Added complete Claude model pricing to LlmUsage. Verified cost calculation works for all Anthropic models. Used base model names in pricing (prefix matching handles versions).

---

### Phase 5: Settings Model

**Goal**: Add Anthropic settings fields with ENV fallbacks
**Depends on**: Phase 4
**Plans**: 3 plans

Plans:
- [x] 5-01: Add anthropic_access_token and anthropic_model fields to Setting
- [x] 5-02: Add llm_provider field for provider selection (openai/anthropic)
- [x] 5-03: Add validation for Anthropic configuration

**Status**: Complete (2026-01-09)

**Details:**
Added anthropic_access_token field with ANTHROPIC_API_KEY ENV default. Added anthropic_model field with ANTHROPIC_MODEL ENV default. Added LLM_PROVIDERS constant defining valid provider values (%w[openai anthropic]). Added llm_provider field with LLM_PROVIDER ENV default (openai fallback). Updated Provider::Registry.anthropic to use Setting method calls. Added validate_llm_provider! validation method to Setting model. Default provider is "openai" for backward compatibility.

---

### Phase 6: Settings UI

**Goal**: Build provider selector dropdown and Anthropic configuration form
**Depends on**: Phase 5
**Plans**: 4 plans

Plans:
- [x] 6-01: Add provider selector dropdown to self-hosting settings
- [x] 6-02: Add Anthropic API key and model input fields
- [x] 6-03: Show/hide fields based on selected provider
- [x] 6-04: Add configuration validation and error messages

**Status**: Complete (2026-01-09) - All 4 plans finished

**Details:**
Created _anthropic_settings.html.erb partial matching OpenAI structure. Created provider_visibility_controller.js Stimulus controller for dynamic show/hide. Added i18n locale strings for all labels and help text. Integrated into hosting settings view. Placed in General section alongside OpenAI settings.

---

### Phase 7: Langfuse Integration

**Goal**: Ensure observability tracing works for Anthropic requests
**Depends on**: Phase 3
**Plans**: 1 plan (consolidated from 2)

Plans:
- [x] 7-01: Adapt Langfuse tracing for Anthropic requests (VERIFICATION - already implemented in Phases 02-03)

**Status**: Complete (2026-01-10) - Verification confirmed Langfuse integration was already implemented correctly. No code changes needed.

**Details:**
Verified langfuse_client initialization follows Provider::Openai pattern. Confirmed all trace names use "anthropic." prefix for Langfuse UI filtering. Verified token field mapping (Anthropic's input/output_tokens -> prompt/completion_tokens). Confirmed error handling prevents Langfuse failures from breaking application. Documented that all three operations (auto_categorize, auto_detect_merchants, chat_response) have Langfuse tracing.

---

### Phase 8: Validation & Testing

**Goal**: Verify all features work and no OpenAI regressions
**Depends on**: Phase 7, Phase 6
**Plans**: 3 plans

Plans:
- [x] 8-01: Test all AI features with Anthropic provider
- [x] 8-02: Test all AI features with OpenAI provider (regression check)
- [x] 8-03: Test provider switching and settings UI

**Status**: Complete (2026-01-10)

**Details:**
Fixed Anthropic SDK compatibility issues preventing tests from passing (symbol keys, array handling, function_results format). Generated VCR cassettes with real Anthropic API calls. All 11 Anthropic provider tests passing (auto_categorize, auto_detect_merchants, chat, function calls, errors, effective_model). Verified all OpenAI functionality remains intact after Anthropic integration with 56 passing tests across 4 test files. Created comprehensive LlmUsage pricing tests covering OpenAI and Anthropic models. Fixed critical bug where chats would always use OpenAI even when Anthropic was selected as the provider. Added comprehensive Setting model tests for llm_provider and Anthropic fields. Added registry tests for LLM provider selection. Added controller tests for Anthropic settings updates.

---

### Phase 9: Resolve Anthropic Issues

**Goal**: Fix any remaining bugs or integration issues discovered during testing
**Depends on**: Phase 8
**Plans**: 1 plan

Plans:
- [x] 9-01: Feature sweep and issue resolution

**Status**: Complete (2026-01-10)

**Details:**
Created 08-03-SUMMARY.md documenting the provider switching work. Performed full feature sweep of all Anthropic functionality. Fixed VCR test failures caused by ANTHROPIC_BASE_URL environment variable pointing to proxy. Wrapped VCR tests with ClimateControl to clear ANTHROPIC_BASE_URL for cassette matching. Created ISSUES.md cataloging all discovered bugs and resolutions. All tests now passing (69 tests, 162 assertions).

---

### Phase 9.1: Fix get_transactions function tool (INSERTED)

**Goal**: Fix "unknown attribute 'page' for Transaction::Search" error in AI chat function calling
**Depends on**: Phase 9
**Plans**: 1 plan

Plans:
- [x] 9.1-01: Handle symbol-keyed params from Anthropic in GetTransactions#call

**Status**: Complete (2026-01-10)

**Details:**
The AI chat was failing when calling the get_transactions function because Anthropic Claude passes page and order with symbol keys (not string keys like OpenAI). Fixed by updating params.except("order", "page") to params.except("order", "page", :order, :page) and using fallback pattern for params access.

---

## Milestone Summary

**Decimal Phases:**
- Phase 9.1: Fix get_transactions function tool (inserted after Phase 9 for urgent fix)

**Key Decisions:**
- Used official anthropic gem (not community ruby-anthropic) for long-term support
- DEFAULT_MODEL = "claude-sonnet-4-5-20250929" (balanced model for categorization/merchant detection)
- Used Anthropic's separate "system" parameter for instructions (Anthropic convention) rather than including in messages array
- Used base model names in pricing (prefix matching handles versions)
- ENV key is "ANTHROPIC_API_KEY" (Anthropic convention) not "ANTHROPIC_ACCESS_TOKEN"
- Default provider is "openai" for backward compatibility
- Placed Anthropic settings in General section alongside OpenAI settings

**Issues Resolved:**
- Fixed ChatParser symbol key mismatch (Anthropic BaseModel uses symbol keys, not string keys)
- Fixed "no implicit conversion of String into Integer" in extract methods (API sometimes returns direct arrays)
- Fixed function_results format for Anthropic multi-turn conversations
- Fixed provider switching to respect llm_provider setting
- Fixed Anthropic BaseModel usage handling (access attributes directly instead of using dig on hash)
- Fixed VCR tests failing due to ANTHROPIC_BASE_URL proxy environment variable
- Fixed get_transactions function tool to handle symbol-keyed params from Anthropic

**Technical Debt Incurred:**
- Streaming support for chat responses was deferred to future work (Phase 3-04)
- Child tool observation spans for tool_use blocks in Langfuse identified as future enhancement

---

**Stats:**
- 62 files changed
- 6,372 lines added
- 11 lines removed
- 10 phases
- 26 plans
- 59 milestone-related commits
- ~1 day development time (2026-01-09 → 2026-01-10)

---

_For current project status, see .planning/ROADMAP.md_
