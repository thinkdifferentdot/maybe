---
phase: 03-chat-support
plan: 04
type: execute
domain: rails-models
---

<objective>
Add streaming support to Anthropic chat_response.

Purpose: Enable real-time streaming of Claude responses for a more natural conversation experience, following the context emphasis on "natural conversation feel."

Output: Working streaming chat with incremental text delivery via streamer proc.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/phase-prompt.md
~/.claude/get-shit-done/references/plan-format.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-chat-support/03-CONTEXT.md
@.planning/phases/03-chat-support/03-RESEARCH.md
@.planning/phases/03-chat-support/03-01-PLAN.md
@.planning/phases/03-chat-support/03-02-PLAN.md
@.planning/phases/03-chat-support/03-03-PLAN.md
@app/models/provider/anthropic.rb
@app/models/provider/anthropic/chat_parser.rb
@app/models/provider/openai/chat_stream_parser.rb
@app/models/provider/llm_concept.rb

**Tech stack available:** anthropic gem ~> 1.16.0, full chat with tools from 03-03
**Established patterns:** OpenAI streaming with ChatStreamParser, ChatStreamChunk format

**Constraining decisions:**
- Phase 3-03: Multi-turn conversation structure established
- Phase 3-01: Token field mapping established
- Context: "Natural conversation feel" is priority, streaming supports this

**Key decisions from RESEARCH.md:**
- Use anthropic.messages.stream for streaming
- stream.text.each helper provides incremental text chunks
- Event types: content_block_start, content_block_delta, message_delta
- For tool use streaming: need to handle tool_use events
- Simpler approach: Use stream.text helper for text-only, manual event parsing for tools

**Note from CONTEXT.md:**
"Streaming may be deferred — the roadmap lists it as optional ('if feasible'). The natural feel matters more than streaming initially."

This plan is marked optional - implement if time allows, otherwise defer to future enhancement.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Provider::Anthropic::ChatStreamParser</name>
  <files>app/models/provider/anthropic/chat_stream_parser.rb</files>
  <action>Create ChatStreamParser class following Openai::ChatStreamParser pattern but adapted for Anthropic streaming events:

Anthropic stream events (from official SDK):
- content_block_start: New content block starting (text or tool_use)
- content_block_delta: Incremental content update
- message_delta: Message-level updates (stop_reason, usage)
- message_stop: Stream complete

Implementation:
1. Initialize with stream event (Hash from SDK)
2. Define parsed method returning Provider::LlmConcept::ChatStreamChunk:
   - type: "output_text" for text deltas
   - type: "response" for completed message
   - data: text content or ChatResponse object
   - usage: token counts (only in response chunk)

3. Handle text deltas:
   - event.type == "content_block_delta" && event.delta.type == "text_delta"
   - Extract event.delta.text for data
   - Return Chunk with type: "output_text"

4. Handle completion:
   - event.type == "message_delta" (includes usage)
   - Accumulate all text deltas to build final ChatResponse
   - Return Chunk with type: "response", data: ChatResponse, usage: usage

5. For tool use in streaming:
   - content_block_start with index/type == "tool_use"
   - Need to accumulate tool use blocks
   - This is complex - consider deferring tool use streaming

Simplify for initial implementation:
- Support text-only streaming first
- Defer tool use streaming to future enhancement
- If tools are requested, fall back to non-streaming

Note: Anthropic's streaming is more complex than OpenAI's. Consider whether full streaming is feasible for this phase.</action>
  <verify>ChatStreamParser converts Anthropic stream events to ChatStreamChunk format</verify>
  <done>ChatStreamParser handles text streaming events correctly</done>
</task>

<task type="auto">
  <name>Task 2: Update chat_response to support streaming</name>
  <files>app/models/provider/anthropic.rb</files>
  <action>Update chat_response to handle streaming when streamer proc is provided:

1. Add streaming branch after ChatConfig setup:
   ```ruby
   if streamer.present?
     streamed_chat_response(...)
   else
     # existing non-streaming code
   end
   ```

2. Implement streamed_chat_response method:
   - Use client.messages.stream instead of client.messages.create
   - Same parameters: model, max_tokens, messages, system, tools
   - Wrap in with_provider_response

3. Create stream proxy proc:
   ```ruby
   stream_proxy = proc do |event|
     parsed_chunk = ChatStreamParser.new(event).parsed
     streamer.call(parsed_chunk) if parsed_chunk
   end
   ```

4. Collect chunks for final response:
   - Track text chunks for output
   - Track response chunk for final ChatResponse
   - Extract usage from message_delta event

5. Handle Langfuse and LlmUsage:
   - Log generation after stream completes
   - Record usage from final event

6. Fall back to non-streaming for tool use:
   - If tools are requested, use non-streaming
   - Tool use streaming is complex, defer to future

7. Error handling:
   - Rescue streaming errors
   - Log to Langfuse with error
   - Record failed LlmUsage

Return ChatResponse from accumulated chunks at stream end.</action>
  <verify>Streaming works for text-only conversations, falls back to non-streaming for tools</verify>
  <done>chat_response supports streaming via streamer proc</done>
</task>

<task type="checkpoint:decision" gate="blocking">
  <decision>Should streaming be deferred to a future phase?</decision>
  <context>The CONTEXT.md emphasizes "natural conversation feel" but also states "Streaming may be deferred — the roadmap lists it as optional ('if feasible')."</context>
  <options>
    <option id="implement-now">
      <name>Implement streaming now</name>
      <pros>Complete phase as planned, better UX, fulfills context emphasis on natural feel</pros>
      <cons>More complex, Anthropic streaming is different from OpenAI, tool use streaming is complex</cons>
    </option>
    <option id="defer">
      <name>Defer streaming to future enhancement</name>
      <pros>Simpler implementation, focus on core functionality first, can add later</pros>
      <cons>Phase incomplete per roadmap, less natural feel initially</cons>
    </option>
  </options>
  <resume-signal>Select: implement-now or defer</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete (if implementing now):
- [ ] ChatStreamParser converts Anthropic events to ChatStreamChunk
- [ ] chat_response uses stream.text.each for incremental text
- [ ] Streamer proc receives text chunks in real-time
- [ ] Final response chunk includes usage
- [ ] Falls back to non-streaming for tool use
- [ ] Langfuse and LlmUsage still work with streaming

If deferring:
- [ ] Document decision to defer streaming
- [ ] Add TODO comment for future streaming implementation
- [ ] Phase still marked complete (streaming was optional)
</verification>

<success_criteria>

- All tasks completed OR streaming deferred with documentation
- If implemented: Streaming works for text conversations
- If deferred: Clear path for future implementation
- No errors or warnings introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/03-chat-support/03-04-SUMMARY.md`:

# Phase 3 Plan 4: Streaming Support Summary

**[Implemented/Deferred] streaming support for Anthropic chat_response**

## Accomplishments

- [If implemented] Created ChatStreamParser for Anthropic streaming events
- [If implemented] Updated chat_response to support streaming via streamer proc
- [If deferred] Documented decision to defer streaming to future enhancement

## Files Created/Modified

- `app/models/provider/anthropic/chat_stream_parser.rb` - [If implemented]
- `app/models/provider/anthropic.rb` - Updated with streaming support

## Decisions Made

- [If implemented] Streaming works for text-only, tool use uses non-streaming
- [If implemented] Used stream.text.each helper for simpler implementation
- [If deferred] Streaming deferred to focus on core functionality

## Issues Encountered

[Document any issues with streaming implementation]

## Next Phase Readiness

Phase 3 complete or ready for next phase:
- If all 4 plans complete: Phase 3 complete, ready for Phase 4 (Registry Integration)
- If 03-04 deferred: Phase 3 complete per decision, ready for Phase 4
</output>
