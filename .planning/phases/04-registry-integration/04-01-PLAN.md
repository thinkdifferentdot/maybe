---
phase: 04-registry-integration
plan: 01
type: execute
domain: rails-models
---

<objective>
Register Anthropic as an "equal citizen" to OpenAI in the provider registry and add accurate cost tracking for Claude models.

Purpose: Make Anthropic discoverable and trackable through the same systems as OpenAI — provider registry for instantiation/discovery and LlmUsage for cost calculation.

Output: Anthropic available via Provider::Registry, discoverable for LLM concept, with accurate per-model pricing in LlmUsage.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/phase-prompt.md
~/.claude/get-shit-done/references/plan-format.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-registry-integration/04-CONTEXT.md
@.planning/phases/04-registry-integration/04-RESEARCH.md
@.planning/phases/02-core-operations/02-02-SUMMARY.md
@.planning/phases/03-chat-support/03-01-PLAN.md
@app/models/provider/registry.rb
@app/models/llm_usage.rb
@app/models/provider/anthropic.rb

**Tech stack available:** anthropic gem ~> 1.16.0, Provider::Anthropic class (from Phase 1)
**Established patterns:** Registry provider methods with ENV → Setting fallback, LlmUsage PRICING hash with prefix matching, available_providers case statement

**Constraining decisions:**
- Phase 1-01: anthropic gem version ~> 1.16.0
- Phase 1-02: DEFAULT_MODEL is "claude-sonnet-4-5-20250929"
- Phase 1-03: Provider::Anthropic initialized with access_token and model parameters

**Key decisions from RESEARCH.md:**
- Follow OpenAI registry pattern exactly: ENV.presence || Setting.model_key
- Use base model names in pricing (e.g., "claude-sonnet-4"), prefix matching handles versions
- Anthropic uses "input/output" terminology, map to "prompt/completion" for consistency
- Pricing per 1M tokens (same as OpenAI)

**Issues being addressed:** None
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add anthropic method to Provider::Registry</name>
  <files>app/models/provider/registry.rb</files>
  <action>Add a private `anthropic` class method to Provider::Registry following the exact pattern of the `openai` method (lines 65-79):

```ruby
def anthropic
  access_token = ENV["ANTHROPIC_API_KEY"].presence || Setting.anthropic_access_token

  return nil unless access_token.present?

  model = ENV["ANTHROPIC_MODEL"].presence || Setting.anthropic_model

  Provider::Anthropic.new(access_token, model: model)
end
```

Key differences from OpenAI:
- No uri_base parameter (Anthropic doesn't support custom endpoints)
- No custom error logging (model is optional, uses Provider::Anthropic default)
- Simpler structure: just access_token and model

Place this method after the `openai` method (after line 79) to keep related LLM providers together.</action>
  <verify>Method exists, returns nil when no API key, instantiates Provider::Anthropic when configured</verify>
  <done>anthropic method follows same ENV → Setting pattern as openai, returns Provider::Anthropic instance or nil</done>
</task>

<task type="auto">
  <name>Task 2: Add anthropic to LLM concept available_providers</name>
  <files>app/models/provider/registry.rb</files>
  <action>Modify the `available_providers` instance method (lines 106-117) to include :anthropic in the :llm case:

Change:
```ruby
when :llm
  %i[openai]
```

To:
```ruby
when :llm
  %i[openai anthropic]
```

This makes Anthropic discoverable via Registry.for_concept(:llm).providers.</action>
  <verify>Registry.for_concept(:llm).providers includes both openai and anthropic (when both are configured)</verify>
  <done>:anthropic symbol added to :llm available_providers array</done>
</task>

<task type="auto">
  <name>Task 3: Add Anthropic pricing to LlmUsage::PRICING</name>
  <files>app/models/llm_usage.rb</files>
  <action>Add Anthropic pricing to the PRICING constant (after line 36, before the "google" entry). Add a new "anthropic" key with Claude model pricing:

```ruby
"anthropic" => {
  "claude-opus-4" => { prompt: 15.00, completion: 75.00 },
  "claude-sonnet-4" => { prompt: 3.00, completion: 15.00 },
  "claude-sonnet-3.7" => { prompt: 3.00, completion: 15.00 },
  "claude-sonnet-3.5" => { prompt: 3.00, completion: 15.00 },
  "claude-haiku-3.5" => { prompt: 0.80, completion: 4.00 },
  "claude-opus-3" => { prompt: 15.00, completion: 75.00 },
  "claude-haiku-3" => { prompt: 0.25, completion: 1.25 },
}
```

Pricing notes:
- All prices are per 1M tokens (same format as OpenAI)
- Prompt = input tokens, Completion = output tokens (Anthropic terminology mapped)
- Base model names only - prefix matching in find_pricing handles versioned names like "claude-sonnet-4-5-20250929"
- Source: Anthropic official pricing docs (as of January 2025)</action>
  <verify>LlmUsage.calculate_cost returns correct values for Anthropic models (e.g., model: "claude-sonnet-4", prompt_tokens: 1000, completion_tokens: 500 returns $0.0105)</verify>
  <done>Anthropic pricing hash added to PRICING constant with all Claude models</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Provider::Registry.anthropic method exists and returns Provider::Anthropic instance or nil
- [ ] Registry.for_concept(:llm).providers includes :anthropic when configured
- [ ] LlmUsage::PRICING includes "anthropic" key with Claude model pricing
- [ ] LlmUsage.calculate_cost works for Anthropic models (test with claude-sonnet-4)
- [ ] LlmUsage.infer_provider returns "anthropic" for Claude model names
- [ ] No Rubocop offenses introduced
- [ ] No test failures
</verification>

<success_criteria>

- All tasks completed
- Anthropic is discoverable via registry (same as OpenAI)
- Cost tracking works for all Claude models
- No regressions to OpenAI provider
  </success_criteria>

<output>
After completion, create `.planning/phases/04-registry-integration/04-01-SUMMARY.md`:

# Phase 4 Plan 1: Registry Integration Summary

**Registered Anthropic as an equal citizen to OpenAI in the provider registry with full cost tracking support**

## Accomplishments

- Added anthropic method to Provider::Registry following OpenAI pattern
- Made Anthropic discoverable for LLM concept
- Added complete Claude model pricing to LlmUsage
- Verified cost calculation works for all Anthropic models

## Files Created/Modified

- `app/models/provider/registry.rb` - Added anthropic method, updated available_providers
- `app/models/llm_usage.rb` - Added Anthropic pricing hash

## Decisions Made

- Used base model names in pricing (prefix matching handles versions)
- Followed exact OpenAI pattern for ENV → Setting fallback
- Mapped Anthropic input/output to prompt/completion for consistency

## Issues Encountered

[None expected, document any issues that arise]

## Next Step

Phase 4 complete, ready for Phase 5 (Settings Model) - Add anthropic_access_token, anthropic_model, and llm_provider fields to Setting model
</output>
